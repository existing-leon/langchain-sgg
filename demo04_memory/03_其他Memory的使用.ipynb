{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1、ConversationTokenBufferMemory的使用"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36cd883a53bfad88"
  },
  {
   "cell_type": "markdown",
   "source": [
    "举例1："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe4b33d9717c55ee"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': ''}\n"
     ]
    }
   ],
   "source": [
    "# 1.导入相关包\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv('OPENAI_BASE_URL')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 2.创建大模型\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 3.定义ConversationTokenBufferMemory对象\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=llm,  # 需要计算token的数量, 所以需要传入大模型\n",
    "    max_token_limit=10  # 设置token上限, 默认值为2000\n",
    ")\n",
    "\n",
    "# 添加对话\n",
    "memory.save_context({\"input\": \"你好吗？\"}, {\"output\": \"我很好，谢谢！\"})\n",
    "memory.save_context({\"input\": \"今天天气如何？\"}, {\"output\": \"晴天，25度\"})\n",
    "\n",
    "# 查看当前记忆\n",
    "print(memory.load_memory_variables({}))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T07:53:57.635342Z",
     "start_time": "2025-11-11T07:53:57.331348Z"
    }
   },
   "id": "7986090f14219f5f",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "举例2："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bd036bcbd4f20f6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'AI: 晴天，25度'}\n"
     ]
    }
   ],
   "source": [
    "# 1.导入相关包\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv('OPENAI_BASE_URL')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 2.创建大模型\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 3.定义ConversationTokenBufferMemory对象\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=llm,  # 需要计算token的数量, 所以需要传入大模型\n",
    "    max_token_limit=20  # 设置token上限, 默认值为2000\n",
    ")\n",
    "\n",
    "# 添加对话\n",
    "memory.save_context({\"input\": \"你好吗？\"}, {\"output\": \"我很好，谢谢！\"})\n",
    "memory.save_context({\"input\": \"今天天气如何？\"}, {\"output\": \"晴天，25度\"})\n",
    "\n",
    "# 查看当前记忆\n",
    "print(memory.load_memory_variables({}))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T07:59:09.739238Z",
     "start_time": "2025-11-11T07:59:09.556113Z"
    }
   },
   "id": "c31ce2ab32ded381",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2、ConversationSummaryMemory的使用"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "444f75411723496"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "举例1：如果实例化ConversationSummaryMemory前, 没有历史消息, 可以使用构造方法实例化"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "478d0f606223e1ee"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'The human greets the AI in Chinese with \"你好\" (hello), and the AI responds with \"怎么了\" (what\\'s wrong?). The human then asks, \"你是谁\" (who are you?), to which the AI replies, \"我是AI助手小智\" (I am AI assistant Xiao Zhi). The human then asks for an introduction, and the AI describes itself as \"一个无所不能的小智\" (a capable assistant).'}\n"
     ]
    }
   ],
   "source": [
    "# 1.导入相关包\n",
    "from langchain.memory import ConversationSummaryMemory, ChatMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 2.创建大模型\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 3.定义ConversationSummaryMemory对象\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "# 4.存储消息\n",
    "memory.save_context({\"input\": \"你好\"}, {\"output\": \"怎么了\"})\n",
    "memory.save_context({\"input\": \"你是谁\"}, {\"output\": \"我是AI助手小智\"})\n",
    "memory.save_context({\"input\": \"初次对话，你能介绍一下你自己吗？\"}, {\"output\": \"当然可以了。我是一个无所不能的小智。\"})\n",
    "\n",
    "# 5.读取消息（总结后的）\n",
    "print(memory.load_memory_variables({}))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T08:05:59.931868Z",
     "start_time": "2025-11-11T08:05:54.132006Z"
    }
   },
   "id": "31fcdb4cb77a3a51",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "举例2：如果实例化ConversationSummaryMemory前，已经有历史消息，可以调用from_messages()实例化"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2527294e4bf343d6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'The human greets and asks the AI who it is. The AI responds that it is the AI assistant named Xiao Zhi.'}\n",
      "{'history': 'The human greets the AI and asks who it is. The AI responds that it is the AI assistant named Xiao Zhi. The human introduces themselves as Xiao Ming, and the AI replies that it is pleased to meet them.'}\n",
      "[HumanMessage(content='你好，你是谁？', additional_kwargs={}, response_metadata={}), AIMessage(content='我是AI助手小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的名字叫小明', additional_kwargs={}, response_metadata={}), AIMessage(content='很高兴认识你', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# 1.导入相关包\n",
    "from langchain.memory import ConversationSummaryMemory, ChatMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 2.定义ChatMessageHistory对象\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 3.假设原始消息\n",
    "history = ChatMessageHistory()\n",
    "history.add_user_message(\"你好，你是谁？\")\n",
    "history.add_ai_message(\"我是AI助手小智\")\n",
    "\n",
    "# 4.初始化ConversationSummaryMemory实例\n",
    "memory = ConversationSummaryMemory.from_messages(\n",
    "    llm=llm,\n",
    "    # 是生成摘要的原材料 保留完整对话供必要时回溯。当新增对话时，LLM需要结合原始历史生成新摘要\n",
    "    chat_memory=history,\n",
    ")\n",
    "\n",
    "print(memory.load_memory_variables({}))\n",
    "print()\n",
    "\n",
    "memory.save_context(inputs={\"human\": \"我的名字叫小明\"}, outputs={\"AI\": \"很高兴认识你\"})\n",
    "print(memory.load_memory_variables({}))\n",
    "\n",
    "# 记录了历史交互的信息\n",
    "print(memory.chat_memory.messages)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T08:37:43.996094Z",
     "start_time": "2025-11-11T08:37:40.448901Z"
    }
   },
   "id": "2b083ca15e06af16",
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
