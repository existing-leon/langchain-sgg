{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1、ConversationTokenBufferMemory的使用"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36cd883a53bfad88"
  },
  {
   "cell_type": "markdown",
   "source": [
    "举例1："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe4b33d9717c55ee"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': ''}\n"
     ]
    }
   ],
   "source": [
    "# 1.导入相关包\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv('OPENAI_BASE_URL')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 2.创建大模型\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 3.定义ConversationTokenBufferMemory对象\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=llm,  # 需要计算token的数量, 所以需要传入大模型\n",
    "    max_token_limit=10  # 设置token上限, 默认值为2000\n",
    ")\n",
    "\n",
    "# 添加对话\n",
    "memory.save_context({\"input\": \"你好吗？\"}, {\"output\": \"我很好，谢谢！\"})\n",
    "memory.save_context({\"input\": \"今天天气如何？\"}, {\"output\": \"晴天，25度\"})\n",
    "\n",
    "# 查看当前记忆\n",
    "print(memory.load_memory_variables({}))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T07:53:57.635342Z",
     "start_time": "2025-11-11T07:53:57.331348Z"
    }
   },
   "id": "7986090f14219f5f",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "举例2："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bd036bcbd4f20f6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'AI: 晴天，25度'}\n"
     ]
    }
   ],
   "source": [
    "# 1.导入相关包\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv('OPENAI_BASE_URL')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 2.创建大模型\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 3.定义ConversationTokenBufferMemory对象\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=llm,  # 需要计算token的数量, 所以需要传入大模型\n",
    "    max_token_limit=20  # 设置token上限, 默认值为2000\n",
    ")\n",
    "\n",
    "# 添加对话\n",
    "memory.save_context({\"input\": \"你好吗？\"}, {\"output\": \"我很好，谢谢！\"})\n",
    "memory.save_context({\"input\": \"今天天气如何？\"}, {\"output\": \"晴天，25度\"})\n",
    "\n",
    "# 查看当前记忆\n",
    "print(memory.load_memory_variables({}))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T07:59:09.739238Z",
     "start_time": "2025-11-11T07:59:09.556113Z"
    }
   },
   "id": "c31ce2ab32ded381",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2、ConversationSummaryMemory的使用"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "444f75411723496"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "举例1：如果实例化ConversationSummaryMemory前, 没有历史消息, 可以使用构造方法实例化"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "478d0f606223e1ee"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'The human greets the AI in Chinese with \"你好\" (hello), and the AI responds with \"怎么了\" (what\\'s wrong?). The human then asks, \"你是谁\" (who are you?), to which the AI replies, \"我是AI助手小智\" (I am AI assistant Xiao Zhi). The human then asks for an introduction, and the AI describes itself as \"一个无所不能的小智\" (a capable assistant).'}\n"
     ]
    }
   ],
   "source": [
    "# 1.导入相关包\n",
    "from langchain.memory import ConversationSummaryMemory, ChatMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 2.创建大模型\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 3.定义ConversationSummaryMemory对象\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "# 4.存储消息\n",
    "memory.save_context({\"input\": \"你好\"}, {\"output\": \"怎么了\"})\n",
    "memory.save_context({\"input\": \"你是谁\"}, {\"output\": \"我是AI助手小智\"})\n",
    "memory.save_context({\"input\": \"初次对话，你能介绍一下你自己吗？\"}, {\"output\": \"当然可以了。我是一个无所不能的小智。\"})\n",
    "\n",
    "# 5.读取消息（总结后的）\n",
    "print(memory.load_memory_variables({}))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T08:05:59.931868Z",
     "start_time": "2025-11-11T08:05:54.132006Z"
    }
   },
   "id": "31fcdb4cb77a3a51",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "举例2：如果实例化ConversationSummaryMemory前，已经有历史消息，可以调用from_messages()实例化"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2527294e4bf343d6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'The human greets and asks the AI who it is. The AI responds that it is the AI assistant named Xiao Zhi.'}\n",
      "{'history': 'The human greets the AI and asks who it is. The AI responds that it is the AI assistant named Xiao Zhi. The human introduces themselves as Xiao Ming, and the AI replies that it is pleased to meet them.'}\n",
      "[HumanMessage(content='你好，你是谁？', additional_kwargs={}, response_metadata={}), AIMessage(content='我是AI助手小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的名字叫小明', additional_kwargs={}, response_metadata={}), AIMessage(content='很高兴认识你', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# 1.导入相关包\n",
    "from langchain.memory import ConversationSummaryMemory, ChatMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 2.定义ChatMessageHistory对象\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 3.假设原始消息\n",
    "history = ChatMessageHistory()\n",
    "history.add_user_message(\"你好，你是谁？\")\n",
    "history.add_ai_message(\"我是AI助手小智\")\n",
    "\n",
    "# 4.初始化ConversationSummaryMemory实例\n",
    "memory = ConversationSummaryMemory.from_messages(\n",
    "    llm=llm,\n",
    "    # 是生成摘要的原材料 保留完整对话供必要时回溯。当新增对话时，LLM需要结合原始历史生成新摘要\n",
    "    chat_memory=history,\n",
    ")\n",
    "\n",
    "print(memory.load_memory_variables({}))\n",
    "print()\n",
    "\n",
    "memory.save_context(inputs={\"human\": \"我的名字叫小明\"}, outputs={\"AI\": \"很高兴认识你\"})\n",
    "print(memory.load_memory_variables({}))\n",
    "\n",
    "# 记录了历史交互的信息\n",
    "print(memory.chat_memory.messages)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T08:37:43.996094Z",
     "start_time": "2025-11-11T08:37:40.448901Z"
    }
   },
   "id": "2b083ca15e06af16",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3、ConversationSummaryBufferMemory的使用"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7242eaa301a64622"
  },
  {
   "cell_type": "markdown",
   "source": [
    "举例1："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69b5d8a713f21f5e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [SystemMessage(content='The human introduces themselves as 小明 (Xiao Ming). The AI expresses pleasure in meeting them, and the human asks which dynasty the poet Li Bai belongs to.', additional_kwargs={}, response_metadata={}), AIMessage(content='李白是唐代诗人', additional_kwargs={}, response_metadata={}), HumanMessage(content='唐宋八大家里有苏轼吗？', additional_kwargs={}, response_metadata={}), AIMessage(content='有', additional_kwargs={}, response_metadata={})]}\n",
      "\n",
      "\n",
      "[AIMessage(content='李白是唐代诗人', additional_kwargs={}, response_metadata={}), HumanMessage(content='唐宋八大家里有苏轼吗？', additional_kwargs={}, response_metadata={}), AIMessage(content='有', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "# 获取大模型\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "# 实例化 ConversationSummaryBufferMemory\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=40,  # 最大缓存区大小, 通过token数限制, 默认是2000\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# 向memory中存储信息\n",
    "memory.save_context(inputs={'input': '你好, 我的名字叫小明'}, outputs={'output': '很高兴认识你, 小明'})\n",
    "memory.save_context(inputs={'input': '李白是哪个朝代的诗人'}, outputs={'output': '李白是唐代诗人'})\n",
    "memory.save_context(inputs={'input': '唐宋八大家里有苏轼吗？'}, outputs={'output': '有'})\n",
    "\n",
    "# 读取memory中保存的内容\n",
    "print(memory.load_memory_variables({}))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# 查看完整的信息内容\n",
    "print(memory.chat_memory.messages)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T09:12:28.363394Z",
     "start_time": "2025-11-11T09:12:23.780457Z"
    }
   },
   "id": "577fbb1fb1ad803a",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "对比组"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd9987e6480211a1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='你好, 我的名字叫小明', additional_kwargs={}, response_metadata={}), AIMessage(content='很高兴认识你, 小明', additional_kwargs={}, response_metadata={}), HumanMessage(content='李白是哪个朝代的诗人', additional_kwargs={}, response_metadata={}), AIMessage(content='李白是唐代诗人', additional_kwargs={}, response_metadata={}), HumanMessage(content='唐宋八大家里有苏轼吗？', additional_kwargs={}, response_metadata={}), AIMessage(content='有', additional_kwargs={}, response_metadata={})]}\n",
      "\n",
      "\n",
      "[HumanMessage(content='你好, 我的名字叫小明', additional_kwargs={}, response_metadata={}), AIMessage(content='很高兴认识你, 小明', additional_kwargs={}, response_metadata={}), HumanMessage(content='李白是哪个朝代的诗人', additional_kwargs={}, response_metadata={}), AIMessage(content='李白是唐代诗人', additional_kwargs={}, response_metadata={}), HumanMessage(content='唐宋八大家里有苏轼吗？', additional_kwargs={}, response_metadata={}), AIMessage(content='有', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "# 获取大模型\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "# 实例化 ConversationSummaryBufferMemory\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=100,  # 最大缓存区大小, 通过token数限制, 默认是2000\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# 向memory中存储信息\n",
    "memory.save_context(inputs={'input': '你好, 我的名字叫小明'}, outputs={'output': '很高兴认识你, 小明'})\n",
    "memory.save_context(inputs={'input': '李白是哪个朝代的诗人'}, outputs={'output': '李白是唐代诗人'})\n",
    "memory.save_context(inputs={'input': '唐宋八大家里有苏轼吗？'}, outputs={'output': '有'})\n",
    "\n",
    "# 读取memory中保存的内容\n",
    "print(memory.load_memory_variables({}))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# 查看完整的信息内容\n",
    "print(memory.chat_memory.messages)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T09:14:15.219046Z",
     "start_time": "2025-11-11T09:14:15.038812Z"
    }
   },
   "id": "5e32351bb8838bb2",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "举例2：模拟客服交互"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52ce767151546083"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户: 你好，我想查询订单12345的状态\n",
      "客服: 你好！感谢您联系我。关于订单12345的状态，我需要查找一下相关信息。请您稍等片刻，我马上为您查询。\n",
      "用户: 这个订单是上周五下的\n",
      "客服: 谢谢您提供的信息！我会尽快为您查询上周五下的订单12345的状态。请稍等一下。 \n",
      "\n",
      "（假设状态查询结果） \n",
      "\n",
      "经过查询，您的订单12345目前正在处理当中，预计将在接下来的2-3个工作日内发货。如有任何更新，我们会及时通知您。如果您有其他问题或需要进一步的帮助，请随时告诉我！\n",
      "用户: 我现在急着用，能加急处理吗\n",
      "客服: 我理解您急需使用的心情，非常抱歉给您带来了不便。关于加急处理订单的请求，我会尽力帮助您。请您提供一下订单的具体需求，我将联系相关部门，看看是否可以为您加急处理。感谢您的理解与耐心！\n",
      "用户: 等等，我可能记错订单号了，应该是12346\n",
      "客服: 没问题！感谢您及时更正订单号。我会立即查询订单12346的状态。请您稍等一下。 \n",
      "\n",
      "（假设状态查询结果） \n",
      "\n",
      "经过查询，您的订单12346目前正在处理当中，预计将在接下来的2-3个工作日内发货。如果您需要加急处理，我会尽力协助您。请告诉我您的具体需求，我会联系相关部门进行确认。感谢您的耐心！如果还有其他问题，随时可以问我哦！\n",
      "用户: 对了，你们退货政策是怎样的\n",
      "客服: 我们的退货政策如下：\n",
      "\n",
      "1. **退货期限**：一般情况下，您可以在收到商品后的7天内申请退货。\n",
      "2. **退货条件**：商品必须保持未使用状态，包装完整，并附带原始标签和发票。\n",
      "3. **退货流程**：请您联系客服提出退货申请，我们会为您提供退货地址和相关指导。\n",
      "4. **退款方式**：一旦我们收到退回的商品并确认符合退货条件，通常会在7个工作日内处理退款。\n",
      "\n",
      "如果您有具体的商品需要退货，或者还有其他问题，请随时告诉我，我会尽力帮助您！\n",
      "\n",
      "\n",
      "=== 当前记忆内容 ===\n",
      "{'chat_history': [SystemMessage(content='The human inquires about the status of order 12345. The AI acknowledges the request and asks for a moment to retrieve the information. The human specifies that the order was placed the previous Friday. The AI thanks the human for the information and continues to check the status. After retrieving the results, the AI informs the human that order 12345 is currently being processed and is expected to ship within the next 2-3 business days, promising to provide updates and offering further assistance if needed.', additional_kwargs={}, response_metadata={}), HumanMessage(content='我现在急着用，能加急处理吗', additional_kwargs={}, response_metadata={}), AIMessage(content='我理解您急需使用的心情，非常抱歉给您带来了不便。关于加急处理订单的请求，我会尽力帮助您。请您提供一下订单的具体需求，我将联系相关部门，看看是否可以为您加急处理。感谢您的理解与耐心！', additional_kwargs={}, response_metadata={}), HumanMessage(content='等等，我可能记错订单号了，应该是12346', additional_kwargs={}, response_metadata={}), AIMessage(content='没问题！感谢您及时更正订单号。我会立即查询订单12346的状态。请您稍等一下。 \\n\\n（假设状态查询结果） \\n\\n经过查询，您的订单12346目前正在处理当中，预计将在接下来的2-3个工作日内发货。如果您需要加急处理，我会尽力协助您。请告诉我您的具体需求，我会联系相关部门进行确认。感谢您的耐心！如果还有其他问题，随时可以问我哦！', additional_kwargs={}, response_metadata={}), HumanMessage(content='对了，你们退货政策是怎样的', additional_kwargs={}, response_metadata={}), AIMessage(content='我们的退货政策如下：\\n\\n1. **退货期限**：一般情况下，您可以在收到商品后的7天内申请退货。\\n2. **退货条件**：商品必须保持未使用状态，包装完整，并附带原始标签和发票。\\n3. **退货流程**：请您联系客服提出退货申请，我们会为您提供退货地址和相关指导。\\n4. **退款方式**：一旦我们收到退回的商品并确认符合退货条件，通常会在7个工作日内处理退款。\\n\\n如果您有具体的商品需要退货，或者还有其他问题，请随时告诉我，我会尽力帮助您！', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "# 1、初始化大语言模型\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "# 2、定义提示模板\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是电商客服助手，用中文友好回复用户问题。保持专业但亲切的语气。\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 3、创建带摘要缓冲的记忆系统\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=400,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# 4、创建对话链\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "# 5、模拟多轮对话\n",
    "dialogue = [\n",
    "    (\"你好，我想查询订单12345的状态\", None),\n",
    "    (\"这个订单是上周五下的\", None),\n",
    "    (\"我现在急着用，能加急处理吗\", None),\n",
    "    (\"等等，我可能记错订单号了，应该是12346\", None),\n",
    "    (\"对了，你们退货政策是怎样的\", None)\n",
    "]\n",
    "\n",
    "# 6、执行对话\n",
    "for user_input, _ in dialogue:\n",
    "    response = chain.invoke({\"input\": user_input})\n",
    "    print(f\"用户: {user_input}\")\n",
    "    print(f\"客服: {response['text']}\\n\")\n",
    "\n",
    "# 7、查看当前记忆状态\n",
    "print(\"\\n=== 当前记忆内容 ===\")\n",
    "print(memory.load_memory_variables({}))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T09:26:58.930881Z",
     "start_time": "2025-11-11T09:26:46.370702Z"
    }
   },
   "id": "90cac98cf3befa8b",
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
