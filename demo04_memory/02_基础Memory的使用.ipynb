{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1、ChatMessageHistory的使用"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea6fff57d55c1233"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "场景1：记忆存储"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be8a12984b15666e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='你好', additional_kwargs={}, response_metadata={}), AIMessage(content='很高兴认识你', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "# 1、ChatMessageHistory的实例化\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "# 2、添加相关的消息进行存储\n",
    "history.add_user_message('你好')\n",
    "history.add_ai_message('很高兴认识你')\n",
    "\n",
    "# 3、打印存储的消息\n",
    "print(history.messages)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-10T09:40:19.268800Z",
     "start_time": "2025-11-10T09:40:18.244076Z"
    }
   },
   "id": "b71459ea0a9b63b9",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "场景2：对接LLM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8643bc9396c42f60"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 1、获取大模型\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 加载环境变量\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv('OPENAI_BASE_URL')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 创建大模型实例\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-10T10:08:04.028284Z",
     "start_time": "2025-11-10T10:08:02.388528Z"
    }
   },
   "id": "9fa6d7826cdef03f",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据数学运算的优先级，首先进行乘法运算，然后再进行加法运算。因此：\n",
      "\n",
      "1 + 2 * 3 = 1 + 6 = 7\n",
      "\n",
      "所以，结果是 7。\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "# 1、ChatMessageHistory的实例化\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "# 2、添加相关的消息进行存储\n",
    "history.add_user_message('你好')\n",
    "history.add_ai_message('很高兴认识你')\n",
    "history.add_user_message('帮我计算 1 + 2 * 3 = ?')\n",
    "\n",
    "response = llm.invoke(history.messages)\n",
    "print(response.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-10T10:09:53.854970Z",
     "start_time": "2025-11-10T10:09:52.283371Z"
    }
   },
   "id": "7a2395ccb652edfa",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2、ConversationBufferMemory的使用"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa366bd7e6040907"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "举例1：以字符串的形式返回存储的消息"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdc0dee514ed84bf"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: 你好, 我叫小明\\nAI: 很高兴认识你\\nHuman: 帮我回答一下 1 + 2 * 3 = ?\\nAI: 7'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# 1、ConversationBufferMemory的实例化\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# 2、存储相关的消息\n",
    "# input对应的就是用户的消息, output对应的就是AI的消息\n",
    "memory.save_context(inputs={'human': '你好, 我叫小明'}, outputs={'ai': '很高兴认识你'})\n",
    "memory.save_context(inputs={'input': '帮我回答一下 1 + 2 * 3 = ?'}, outputs={'output': '7'})\n",
    "\n",
    "# 3、获取存储的消息\n",
    "print(memory.load_memory_variables({}))\n",
    "\n",
    "# 返回的字典结构的key叫history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T02:46:26.920453Z",
     "start_time": "2025-11-11T02:46:26.897865Z"
    }
   },
   "id": "330046062c023cf6",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "举例2：以消息列表的形式返回存储的消息"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9ee700c8766663"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='你好, 我叫小明', additional_kwargs={}, response_metadata={}), AIMessage(content='很高兴认识你', additional_kwargs={}, response_metadata={}), HumanMessage(content='帮我回答一下 1 + 2 * 3 = ?', additional_kwargs={}, response_metadata={}), AIMessage(content='7', additional_kwargs={}, response_metadata={})]}\n",
      "\n",
      "[HumanMessage(content='你好, 我叫小明', additional_kwargs={}, response_metadata={}), AIMessage(content='很高兴认识你', additional_kwargs={}, response_metadata={}), HumanMessage(content='帮我回答一下 1 + 2 * 3 = ?', additional_kwargs={}, response_metadata={}), AIMessage(content='7', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# 1、ConversationBufferMemory的实例化\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# 2、存储相关的消息\n",
    "# input对应的就是用户的消息, output对应的就是AI的消息\n",
    "memory.save_context(inputs={'human': '你好, 我叫小明'}, outputs={'ai': '很高兴认识你'})\n",
    "memory.save_context(inputs={'input': '帮我回答一下 1 + 2 * 3 = ?'}, outputs={'output': '7'})\n",
    "\n",
    "# 3、获取存储的消息\n",
    "# 返回消息列表的方式1\n",
    "print(memory.load_memory_variables({}))\n",
    "\n",
    "print()\n",
    "\n",
    "# 返回消息列表的方式2\n",
    "print(memory.chat_memory.messages)\n",
    "\n",
    "# 返回的字典结构的key叫history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T02:50:37.940002Z",
     "start_time": "2025-11-11T02:50:37.923052Z"
    }
   },
   "id": "f5806b635ecc99cc",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "举例3：结合提示词模板（PromptTemplate）、大模型的使用"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f15d40f28a43826c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '你好, 我的名字叫小明', 'history': '', 'text': '你好，小明！很高兴认识你！有什么我可以帮助你的吗？'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# 1、创建大模型\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 加载环境变量\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 给系统环境变量赋值\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv('OPENAI_BASE_URL')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 获取大模型\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "# 2、创建提示词模板\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"\"\"你可以与人类对话。\n",
    "    \n",
    "            当前对话历史: {history}\n",
    "            \n",
    "            人类问题: {question}\n",
    "            \n",
    "            回复:\n",
    "            \"\"\"\n",
    ")\n",
    "\n",
    "# 3、提供Memory的实例\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# 4、提供Chain\n",
    "# 此处提示词模板中存在两个变量, 但是只传入了一个question变量却不报错, 是因为memory会返回一个以key为history的值, 会间接传入到提示词中\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template, memory=memory)\n",
    "\n",
    "response = chain.invoke({'question': '你好, 我的名字叫小明'})\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T03:19:51.949234Z",
     "start_time": "2025-11-11T03:19:48.644385Z"
    }
   },
   "id": "3b36ea479910d30c",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '我叫什么名字呢？', 'history': 'Human: 你好, 我的名字叫小明\\nAI: 你好，小明！很高兴认识你！有什么我可以帮助你的吗？', 'text': '你叫小明！很高兴再次见到你！你有什么想聊的呢？'}\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke('我叫什么名字呢？')\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T03:30:06.667878Z",
     "start_time": "2025-11-11T03:30:05.526458Z"
    }
   },
   "id": "d2ec9c690aa4cd8a",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "举例4：基于举例3, 显示得设置memory的key值"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca765713a7f7371d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '你好, 我的名字叫小明', 'chat_history': '', 'text': '你好，小明！很高兴认识你。有什么我可以帮助你的吗？'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# 1、创建大模型\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 加载环境变量\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 给系统环境变量赋值\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv('OPENAI_BASE_URL')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 获取大模型\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "# 2、创建提示词模板\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"\"\"你可以与人类对话。\n",
    "    \n",
    "            当前对话历史: {chat_history}\n",
    "            \n",
    "            人类问题: {question}\n",
    "            \n",
    "            回复:\n",
    "            \"\"\"\n",
    ")\n",
    "\n",
    "# 3、提供Memory的实例\n",
    "# 此处需要将memory_key自定义的值与上面提示词模板中的变量统一起来即可\n",
    "memory = ConversationBufferMemory(memory_key='chat_history')\n",
    "\n",
    "# 4、提供Chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template, memory=memory)\n",
    "\n",
    "response = chain.invoke({'question': '你好, 我的名字叫小明'})\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T03:36:22.339238Z",
     "start_time": "2025-11-11T03:36:20.850984Z"
    }
   },
   "id": "7dabd7de6188b74",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '我叫什么名字呢？', 'chat_history': 'Human: 你好, 我的名字叫小明\\nAI: 你好，小明！很高兴认识你。有什么我可以帮助你的吗？', 'text': '你叫小明。有什么你想聊的吗？'}\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke('我叫什么名字呢？')\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T03:37:55.202869Z",
     "start_time": "2025-11-11T03:37:53.847009Z"
    }
   },
   "id": "a64cbe6b7d40b79f",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "5、结合提示词模板（ChatPromptTemplate）, 大模型使用"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77e8f2b38e385f7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '中国首都在哪里？', 'history': [HumanMessage(content='中国首都在哪里？', additional_kwargs={}, response_metadata={}), AIMessage(content='中国的首都是北京。', additional_kwargs={}, response_metadata={})], 'text': '中国的首都是北京。'}\n"
     ]
    }
   ],
   "source": [
    "# 1.导入相关包\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import MessagesPlaceholder, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 2.创建LLM\n",
    "llm = ChatOpenAI(model_name='gpt-4o-mini')\n",
    "\n",
    "# 3.创建Prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个与人类对话的机器人。\"),\n",
    "    MessagesPlaceholder(variable_name='history'),\n",
    "    (\"human\", \"问题：{question}\")\n",
    "])\n",
    "\n",
    "# 4.创建Memory\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# 5.创建LLMChain\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, memory=memory)\n",
    "\n",
    "# 6.调用LLMChain\n",
    "res1 = llm_chain.invoke({\"question\": \"中国首都在哪里？\"})\n",
    "print(res1, end=\"\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T06:09:21.499297Z",
     "start_time": "2025-11-11T06:09:19.732145Z"
    }
   },
   "id": "b3838a0422ca468e",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '我刚刚问了什么', 'history': [HumanMessage(content='中国首都在哪里？', additional_kwargs={}, response_metadata={}), AIMessage(content='中国的首都是北京。', additional_kwargs={}, response_metadata={}), HumanMessage(content='我刚刚问了什么', additional_kwargs={}, response_metadata={}), AIMessage(content='你问了“中国首都在哪里？”这个问题。', additional_kwargs={}, response_metadata={})], 'text': '你问了“中国首都在哪里？”这个问题。'}\n"
     ]
    }
   ],
   "source": [
    "res2 = llm_chain.invoke({\"question\": \"我刚刚问了什么\"})\n",
    "print(res2, end=\"\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-11T06:09:28.650447Z",
     "start_time": "2025-11-11T06:09:25.291931Z"
    }
   },
   "id": "eb9e6238c2b29313",
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
