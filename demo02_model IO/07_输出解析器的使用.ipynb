{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1、字符串输出解析器 StrOutputParser"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9396aabf1c8686a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "<class 'str'>\n",
      "大语言模型（Large Language Model，LLM）是指一种通过处理大量文本数据来学习语言的高级人工智能模型。这些模型基于深度学习技术，特别是变换器（Transformer）架构，旨在理解和生成自然语言。大语言模型具有以下几个主要特点：\n",
      "\n",
      "1. **规模庞大**：这些模型通常由数亿到数千亿个参数组成，能够捕捉语言中的复杂模式和结构。\n",
      "\n",
      "2. **预训练和微调**：大语言模型通常首先在大型文本语料库上进行预训练，以学习语言的基本知识；然后可以通过微调适应特定的任务，如情感分析、问答、翻译等。\n",
      "\n",
      "3. **上下文理解**：由于使用了大量的数据，语言模型能够在给定上下文的基础上生成连贯且相关的文本。\n",
      "\n",
      "4. **应用广泛**：大语言模型可以用于各种自然语言处理（NLP）任务，包括但不限于文本生成、摘要、对话系统、信息检索等。\n",
      "\n",
      "5. **可迁移性**：经过预训练的模型可以很容易地适应特定领域的任务，减少了从头开始训练的时间和资源消耗。\n",
      "\n",
      "总之，大语言模型是一种强大的工具，能够在多个场景中处理和生成自然语言，为各种应用提供支持。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# 1、获取大模型\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "# 2、调用大模型\n",
    "response = chat_model.invoke(\"什么是大语言模型？\")\n",
    "\n",
    "print(type(response))  # AIMessage\n",
    "# print(response)\n",
    "\n",
    "# 3、如何获取一个字符串类型的结果呢？\n",
    "# 方式①：自己调用输出结果的content\n",
    "# print(response.content)\n",
    "\n",
    "# 方式②：使用 StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "str_response = parser.invoke(response)\n",
    "print(type(str_response))\n",
    "print(str_response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-29T11:20:53.242296Z",
     "start_time": "2025-10-29T11:20:47.966310Z"
    }
   },
   "id": "58ee58d05afff4a3",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2、JSON解析器 JsonOutputParser"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "549bbd8cf4676cc6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "方式1：用户借助自己的提示词指明返回JSON格式"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35d75f5d0dd3e6a6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "```json\n",
      "{\n",
      "  \"q\": \"人工智能用英语怎么说？\",\n",
      "  \"a\": \"Artificial Intelligence\"\n",
      "}\n",
      "```\n",
      "{'q': '人工智能用英语怎么说？', 'a': 'Artificial Intelligence'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "# 1、获取大模型\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "# 根据提示词模板创建提示词\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一个靠谱的{role}\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 2、调用大模型\n",
    "response = chat_model.invoke(\n",
    "    chat_prompt_template.invoke(\n",
    "        {\n",
    "            \"role\": \"人工智能专家\",\n",
    "            \"question\": \"人工智能用英语怎么说？问题用q表示, 答案用a表示, 返回一个JSON格式的数据\"\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "print(response.content)\n",
    "\n",
    "# 获取一个JsonOutputParser的实例\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "json_result = parser.invoke(response)\n",
    "print(json_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-29T11:36:05.988982Z",
     "start_time": "2025-10-29T11:36:03.520009Z"
    }
   },
   "id": "10baf537b67c8dcb",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "方式2：借助JsonOutputParser的get_format_instructions(), 生成格式说明, 指导模型输出JSON结构"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d019fe4970c4e556"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': '为什么计算机很冷？因为它们总是打开窗口！'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 1、获取大模型\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "joke_query = \"告诉我一个笑话。\"\n",
    "\n",
    "# 定义Json解析器\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# 2、定义提示词模版\n",
    "# 注意，提示词模板中需要部分格式化解析器的格式要求format_instructions\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"回答用户的查询.\\n满足的格式为{format_instructions}\\n问题为{question}\\n\",\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke({\"question\": joke_query})\n",
    "\n",
    "# 3、调用大模型获取返回结果\n",
    "response = chat_model.invoke(prompt)\n",
    "json_result = parser.invoke(response)\n",
    "\n",
    "print(json_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-29T11:49:36.521817Z",
     "start_time": "2025-10-29T11:49:35.195575Z"
    }
   },
   "id": "e26117152e8b256f",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 知识的拓展：管道符"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54501f6d9d18d85a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "针对于举例1改造"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddb241f8a2628f05"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q': '人工智能用英语怎么说？', 'a': 'Artificial Intelligence'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "# 1、获取大模型\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "# 根据提示词模板创建提示词\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一个靠谱的{role}\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 获取一个JsonOutputParser的实例\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# 2、调用大模型\n",
    "## 写法1：\n",
    "# response = chat_model.invoke(\n",
    "#     chat_prompt_template.invoke(\n",
    "#         {\n",
    "#             \"role\": \"人工智能专家\",\n",
    "#             \"question\": \"人工智能用英语怎么说？问题用q表示, 答案用a表示, 返回一个JSON格式的数据\"\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "# \n",
    "# json_result = parser.invoke(response)\n",
    "# print(json_result)\n",
    "\n",
    "## 写法2：\n",
    "chain = chat_prompt_template | chat_model | parser\n",
    "json_result_chain = chain.invoke(\n",
    "    {\n",
    "        \"role\": \"人工智能专家\",\n",
    "        \"question\": \"人工智能用英语怎么说？问题用q表示, 答案用a表示, 返回一个JSON格式的数据\"\n",
    "    }\n",
    ")\n",
    "print(json_result_chain)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-29T12:15:05.178472Z",
     "start_time": "2025-10-29T12:15:04.027379Z"
    }
   },
   "id": "9d36fad1862bd2db",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "针对于举例2改造："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cffd7e7552054275"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': 'Why did the scarecrow win an award? Because he was outstanding in his field!'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 1、获取大模型\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "joke_query = \"告诉我一个笑话。\"\n",
    "\n",
    "# 定义Json解析器\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# 2、定义提示词模版\n",
    "# 注意，提示词模板中需要部分格式化解析器的格式要求format_instructions\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"回答用户的查询.\\n满足的格式为{format_instructions}\\n问题为{question}\\n\",\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "## 写法1：\n",
    "# prompt = prompt_template.invoke({\"question\": joke_query})\n",
    "# # 3、调用大模型获取返回结果\n",
    "# response = chat_model.invoke(prompt)\n",
    "# json_result = parser.invoke(response)\n",
    "\n",
    "## 写法2：\n",
    "chain = prompt_template | chat_model | parser\n",
    "json_result_chain = chain.invoke(\n",
    "    {\"question\": joke_query}\n",
    ")\n",
    "\n",
    "print(json_result_chain)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-29T12:18:26.196892Z",
     "start_time": "2025-10-29T12:18:24.860190Z"
    }
   },
   "id": "84953a02a25c77b2",
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
