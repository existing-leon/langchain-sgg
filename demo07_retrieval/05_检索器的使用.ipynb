{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1、基础使用",
   "id": "d58a3e1d73022011"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例",
   "id": "9c9bf507258cc1de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T04:56:47.664957Z",
     "start_time": "2025-11-23T04:56:46.167567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.导入相关依赖\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 2.定义文档加载器\n",
    "loader = TextLoader(file_path='./asset/load/09-ai1.txt', encoding=\"utf-8\")\n",
    "\n",
    "# 3.加载文档\n",
    "documents = loader.load()\n",
    "\n",
    "# 4.定义文本切割器\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "# 5.切割文档\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# 6.定义嵌入模型\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n"
   ],
   "id": "4278d06039b93c86",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T05:03:44.505556Z",
     "start_time": "2025-11-23T05:03:43.724785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "print(\"type(docs[0]) ==>\",type(docs[0]))\n",
    "print(\"type(docs) ==>\",type(docs))\n",
    "print(\"type(embeddings) ==>\",type(embeddings))\n",
    "\n",
    "# 7.将文档存储到向量数据库中\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# 8.从向量数据库中得到检索器\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "# 9.使用检索器检索\n",
    "docs = retriever.invoke(\"深度学习是什么？\")\n",
    "\n",
    "print(len(docs))\n",
    "\n",
    "# 10.得到结果\n",
    "for doc in docs:\n",
    "    print(f\"⭐{doc}\")"
   ],
   "id": "1812a76aef4fc70b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(docs[0]) ==> <class 'langchain_core.documents.base.Document'>\n",
      "type(docs) ==> <class 'list'>\n",
      "type(embeddings) ==> <class 'langchain_openai.embeddings.base.OpenAIEmbeddings'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "input not a numpy array",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_1104\\3456338562.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"type(docs) ==>\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdocs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"type(embeddings) ==>\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0membeddings\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;31m# 7.将文档存储到向量数据库中\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m \u001B[0mdb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mFAISS\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_documents\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdocs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0membeddings\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;31m# 8.从向量数据库中得到检索器\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[0mretriever\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdb\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mas_retriever\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\langchain310\\lib\\site-packages\\langchain_core\\vectorstores\\base.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(cls, documents, embedding, **kwargs)\u001B[0m\n\u001B[0;32m    844\u001B[0m             \u001B[1;31m# should be used.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    845\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0many\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mids\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    846\u001B[0m                 \u001B[0mkwargs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"ids\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mids\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    847\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 848\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mcls\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_texts\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtexts\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0membedding\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmetadatas\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmetadatas\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\.conda\\envs\\langchain310\\lib\\site-packages\\langchain_community\\vectorstores\\faiss.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001B[0m\n\u001B[0;32m   1040\u001B[0m                 \u001B[0membeddings\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mOpenAIEmbeddings\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1041\u001B[0m                 \u001B[0mfaiss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mFAISS\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_texts\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtexts\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0membeddings\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1042\u001B[0m         \"\"\"\n\u001B[0;32m   1043\u001B[0m         \u001B[0membeddings\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0membedding\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membed_documents\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtexts\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1044\u001B[1;33m         return cls.__from(\n\u001B[0m\u001B[0;32m   1045\u001B[0m             \u001B[0mtexts\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1046\u001B[0m             \u001B[0membeddings\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1047\u001B[0m             \u001B[0membedding\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\langchain310\\lib\\site-packages\\langchain_community\\vectorstores\\faiss.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(cls, texts, embeddings, embedding, metadatas, ids, normalize_L2, distance_strategy, **kwargs)\u001B[0m\n\u001B[0;32m   1009\u001B[0m             \u001B[0mnormalize_L2\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnormalize_L2\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1010\u001B[0m             \u001B[0mdistance_strategy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdistance_strategy\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1011\u001B[0m             \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1012\u001B[0m         )\n\u001B[1;32m-> 1013\u001B[1;33m         \u001B[0mvecstore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__add\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtexts\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0membeddings\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmetadatas\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmetadatas\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mids\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mids\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1014\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mvecstore\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\langchain310\\lib\\site-packages\\langchain_community\\vectorstores\\faiss.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, texts, embeddings, metadatas, ids)\u001B[0m\n\u001B[0;32m    309\u001B[0m         \u001B[1;31m# Add to the index.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m         \u001B[0mvector\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0membeddings\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    311\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_normalize_L2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    312\u001B[0m             \u001B[0mfaiss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnormalize_L2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvector\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 313\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvector\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    314\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    315\u001B[0m         \u001B[1;31m# Add information to docstore and index.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    316\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdocstore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[0mid_\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mdoc\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mid_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdoc\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mids\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdocuments\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\langchain310\\lib\\site-packages\\faiss\\class_wrappers.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    226\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    227\u001B[0m         \u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0md\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    228\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0md\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0md\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    229\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mascontiguousarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'float32'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 230\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_c\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mswig_ptr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\.conda\\envs\\langchain310\\lib\\site-packages\\faiss\\swigfaiss.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(a)\u001B[0m\n\u001B[0;32m  13801\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mswig_ptr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m> 13802\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_swigfaiss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mswig_ptr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m: input not a numpy array"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
