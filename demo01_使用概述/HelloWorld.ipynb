{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1、 获取大模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "376d2befb81f2b6e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-53ekLHum39xYYpIbkKJu5SVOtfszs1JVeOuT8xR6kQ7h2gVI\n",
      "https://api.openai-proxy.org/v1\n",
      "content='“大模型”通常指的是参数数量非常庞大的机器学习模型，尤其是在深度学习领域。这类模型通过大量的训练数据和复杂的网络结构来学习并捕捉数据中的潜在模式和规律。大模型通常用于处理自然语言处理、计算机视觉等复杂任务。\\n\\n大模型的特点包括：\\n\\n1. **参数量大**：大模型的参数数量通常在亿级甚至百亿级以上。例如，GPT-3模型就拥有1750亿个参数。\\n   \\n2. **数据需求高**：大模型需要大量的数据进行训练，以避免过拟合并提高泛化能力。\\n\\n3. **计算资源消耗大**：训练和部署大模型通常需要强大的计算资源，包括高性能的GPU和大容量的存储。\\n\\n4. **迁移学习**：大模型的结构允许它们通过迁移学习在新任务上实现良好的性能，即便新任务的数据相对较少。\\n\\n5. **应用广泛**：大模型在自然语言处理（如文本生成、翻译、问答系统）、计算机视觉（如图像分类、目标检测），以及其他各种领域都有广泛应用。\\n\\n尽管大模型在许多任务上展现了强大的性能，但也存在一些挑战，比如训练成本高、推理速度慢、模型可解释性差等。因此，研究人员和工程师们也在探讨更高效的模型架构和训练方法。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 311, 'prompt_tokens': 12, 'total_tokens': 323, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_efad92c60b', 'id': 'chatcmpl-CSdcowE0uMYT4DrmZ0cDpx72b3WW1', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--ba855f49-cee7-4f7a-83ba-1d538baf95b9-0' usage_metadata={'input_tokens': 12, 'output_tokens': 311, 'total_tokens': 323, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "#导入 dotenv 库的 load_dotenv 函数，用于加载环境变量文件（.env）中的配置\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()  #加载当前目录下的 .env 文件\n",
    "print(os.getenv(\"OPENAI_API_KEY1\"))\n",
    "print(os.getenv(\"OPENAI_BASE_URL\"))\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "# os.environ['OPENAI_API_KEY'] = \"sk-53ekLHum39xYYpIbkKJu5SVOtfszs1JVeOuT8xR6kQ7h2gVI\"\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "# 创建大模型实例\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")  # 默认使用 gpt-3.5-turbo\n",
    "# 直接提供问题，并调用llm\n",
    "response = llm.invoke(\"什么是大模型？\")\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-20T06:25:41.831085Z",
     "start_time": "2025-10-20T06:25:37.381445Z"
    }
   },
   "id": "ec2606f02855e93f",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2、使用提示词模板"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5d59b52f77aee2e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangChain 是一个用于构建与大语言模型（如 GPT-3、GPT-4 等）交互的应用程序的框架。它提供了一系列工具和模块，以帮助开发者更高效地创建复杂的语言模型驱动的应用，无论是聊天机器人、文本生成工具还是其他自然语言处理任务。\\n\\n### LangChain 的主要特点：\\n\\n1. **链式调用 (Chain)**: LangChain 的核心思想是将多个处理步骤以链的形式连接起来，使得每一步的输出可以直接作为下一步的输入，从而处理复杂的任务流。\\n\\n2. **数据源管理**: LangChain 支持多种数据源，以便于信息的获取和处理，可以集成数据库、API、文档等多种数据源。\\n\\n3. **记忆 (Memory)**: LangChain 可以在会话中保持上下文记忆，使得应用能够更好地理解和记录用户的行为，提供更个性化的体验。\\n\\n4. **工具集成**: 它允许集成外部工具和服务，比如搜索引擎、计算服务等，增强语言模型的能力。\\n\\n5. **多种模型支持**: LangChain 与多种语言模型兼容，用户可以轻松切换不同的模型来比较性能或满足特定需求。\\n\\n6. **可扩展性**: LangChain 以模块化的方式设计，支持开发者扩展功能，创造自己的自定义模块以适应不同的使用场景。\\n\\n### 应用场景：\\n\\n- **聊天机器人**：通过 LangChain，开发者可以构建能够进行自然对话的智能聊天机器人。\\n- **文本分析和生成**：可以用于内容创作、文本摘要、情感分析等任务。\\n- **知识提取**：从大量文档或数据库中提取有用信息。\\n\\n总之，LangChain 是一个强大且灵活的框架，旨在简化与大语言模型的集成过程，帮助开发者快速构建和部署自然语言处理应用。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 435, 'prompt_tokens': 29, 'total_tokens': 464, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_efad92c60b', 'id': 'chatcmpl-CSagWlGXe5EnPfRdCQCQOApKZRKDh', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--1f4c9e86-b8b3-467c-8a94-a015c8a0fe1f-0' usage_metadata={'input_tokens': 29, 'output_tokens': 435, 'total_tokens': 464, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 需要注意的一点是，这里需要指明具体的role，在这里是system和用户\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是世界级的技术文档编写者\"),\n",
    "    (\"user\", \"{input}\")  # {input}为变量\n",
    "])\n",
    "# 我们可以把prompt和具体llm的调用和在一起。\n",
    "chain = prompt | llm\n",
    "message = chain.invoke({\"input\": \"大模型中的LangChain是什么?\"})\n",
    "print(message)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-20T03:17:19.662603Z",
     "start_time": "2025-10-20T03:17:15.421708Z"
    }
   },
   "id": "2ce7c2a92c6c4f53",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3、使用输出解释器"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ffeddc14ed5dd8e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'question': 'LangChain是什么?',\n 'answer': 'LangChain是一个用于构建与语言模型交互的应用程序的框架。它提供了一套组件和工具，可以帮助开发者轻松创建、管理和优化与自然语言处理(NLP)相关的项目。LangChain支持多种语言模型，并能够与不同的数据源、API和其他服务集成，使开发者能够构建复杂的对话系统和智能应用。'}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "\n",
    "# 初始化模型\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# 创建提示模板\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是世界级的技术文档编写者。\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "# 使用输出解析器\n",
    "# output_parser = StrOutputParser()\n",
    "output_parser = JsonOutputParser()\n",
    "# 将其添加到上一个链中\n",
    "# chain = prompt | llm\n",
    "chain = prompt | llm | output_parser\n",
    "# 调用它并提出同样的问题。答案是一个字符串，而不是ChatMessage\n",
    "# chain.invoke({\"input\": \"LangChain是什么?\"})\n",
    "chain.invoke({\"input\": \"LangChain是什么? 用JSON格式回复，问题用question，回答用answer\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-20T03:17:38.955259Z",
     "start_time": "2025-10-20T03:17:36.958171Z"
    }
   },
   "id": "7746533fdad3d8c2",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4、使用向量存储"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9db47ef38910bff"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://www.12371.cn/2020/06/01/ARTI1591021670041266.shtml'}, page_content='')]\n",
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 28\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(documents))\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# 向量存储 embeddings 会将 documents 中的每个文本片段转换为向量，并将这些向量存储在 FAISS向量数据库中\u001B[39;00m\n\u001B[1;32m---> 28\u001B[0m vector \u001B[38;5;241m=\u001B[39m \u001B[43mFAISS\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\develop\\conda_envs\\langchain310\\lib\\site-packages\\langchain_core\\vectorstores\\base.py:848\u001B[0m, in \u001B[0;36mVectorStore.from_documents\u001B[1;34m(cls, documents, embedding, **kwargs)\u001B[0m\n\u001B[0;32m    845\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(ids):\n\u001B[0;32m    846\u001B[0m         kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mids\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m ids\n\u001B[1;32m--> 848\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mfrom_texts(texts, embedding, metadatas\u001B[38;5;241m=\u001B[39mmetadatas, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\develop\\conda_envs\\langchain310\\lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1042\u001B[0m, in \u001B[0;36mFAISS.from_texts\u001B[1;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001B[0m\n\u001B[0;32m   1023\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001B[39;00m\n\u001B[0;32m   1024\u001B[0m \n\u001B[0;32m   1025\u001B[0m \u001B[38;5;124;03mThis is a user friendly interface that:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;124;03m        faiss = FAISS.from_texts(texts, embeddings)\u001B[39;00m\n\u001B[0;32m   1040\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1041\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m embedding\u001B[38;5;241m.\u001B[39membed_documents(texts)\n\u001B[1;32m-> 1042\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m__from(\n\u001B[0;32m   1043\u001B[0m     texts,\n\u001B[0;32m   1044\u001B[0m     embeddings,\n\u001B[0;32m   1045\u001B[0m     embedding,\n\u001B[0;32m   1046\u001B[0m     metadatas\u001B[38;5;241m=\u001B[39mmetadatas,\n\u001B[0;32m   1047\u001B[0m     ids\u001B[38;5;241m=\u001B[39mids,\n\u001B[0;32m   1048\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   1049\u001B[0m )\n",
      "File \u001B[1;32mD:\\develop\\conda_envs\\langchain310\\lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:999\u001B[0m, in \u001B[0;36mFAISS.__from\u001B[1;34m(cls, texts, embeddings, embedding, metadatas, ids, normalize_L2, distance_strategy, **kwargs)\u001B[0m\n\u001B[0;32m    996\u001B[0m     index \u001B[38;5;241m=\u001B[39m faiss\u001B[38;5;241m.\u001B[39mIndexFlatIP(\u001B[38;5;28mlen\u001B[39m(embeddings[\u001B[38;5;241m0\u001B[39m]))\n\u001B[0;32m    997\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    998\u001B[0m     \u001B[38;5;66;03m# Default to L2, currently other metric types not initialized.\u001B[39;00m\n\u001B[1;32m--> 999\u001B[0m     index \u001B[38;5;241m=\u001B[39m faiss\u001B[38;5;241m.\u001B[39mIndexFlatL2(\u001B[38;5;28mlen\u001B[39m(\u001B[43membeddings\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m))\n\u001B[0;32m   1000\u001B[0m docstore \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocstore\u001B[39m\u001B[38;5;124m\"\u001B[39m, InMemoryDocstore())\n\u001B[0;32m   1001\u001B[0m index_to_docstore_id \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex_to_docstore_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, {})\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# 导入和使用 WebBaseLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    # web_path=\"https://www.gov.cn/xinwen/2020-06/01/content_5516649.htm\",\n",
    "    # bs_kwargs=dict(parse_only=bs4.SoupStrainer(id=\"UCAP-CONTENT\"))\n",
    "    \n",
    "    web_path=\"https://www.12371.cn/2020/06/01/ARTI1591021670041266.shtml\",\n",
    "    bs_kwargs=dict(parse_only=bs4.SoupStrainer(id=\"font-area\"))\n",
    "\n",
    ")\n",
    "docs = loader.load()\n",
    "print(docs)\n",
    "# 对于嵌入模型，这里通过 API调用\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 使用分割器分割文档\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "print(len(documents))\n",
    "# 向量存储 embeddings 会将 documents 中的每个文本片段转换为向量，并将这些向量存储在 FAISS向量数据库中\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-20T06:08:38.036013Z",
     "start_time": "2025-10-20T06:08:37.347994Z"
    }
   },
   "id": "7543f4bcb1167be5",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5、RAG检索增强生成"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3d39b6ecce05dfa"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mlangchain_core\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprompts\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PromptTemplate\n\u001B[1;32m----> 3\u001B[0m retriever \u001B[38;5;241m=\u001B[39m \u001B[43mvector\u001B[49m\u001B[38;5;241m.\u001B[39mas_retriever()\n\u001B[0;32m      4\u001B[0m retriever\u001B[38;5;241m.\u001B[39msearch_kwargs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mk\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m3\u001B[39m}\n\u001B[0;32m      5\u001B[0m docs \u001B[38;5;241m=\u001B[39m retriever\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m建设用地使用权是什么？\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'vector' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retriever.search_kwargs = {\"k\": 3}\n",
    "docs = retriever.invoke(\"建设用地使用权是什么？\")\n",
    "# for i,doc in enumerate(docs):\n",
    "# print(f\"⭐第{i+1}条规定：\")\n",
    "# print(doc)\n",
    "# 6.定义提示词模版\n",
    "prompt_template = \"\"\"\n",
    "你是一个问答机器人。\n",
    "你的任务是根据下述给定的已知信息回答用户问题。\n",
    "确保你的回复完全依据下述已知信息。不要编造答案。\n",
    "如果下述已知信息不足以回答用户的问题，请直接回复\"我无法回答您的问题\"。\n",
    "已知信息:\n",
    "{info}\n",
    "用户问：\n",
    "{question}\n",
    "请用中文回答用户问题。\n",
    "\"\"\"\n",
    "# 7.得到提示词模版对象\n",
    "template = PromptTemplate.from_template(prompt_template)\n",
    "# 8.得到提示词对象\n",
    "prompt = template.format(info=docs, question='建设用地使用权是什么？')\n",
    "\n",
    "## 9. 调用LLM\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-20T03:21:55.529752Z",
     "start_time": "2025-10-20T03:21:55.474182Z"
    }
   },
   "id": "e1c0963e470432d2",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6、使用Agent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "514bc9f4c2ebffa7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "# 检索器工具\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"CivilCodeRetriever\",\n",
    "    \"搜索有关中华人民共和国民法典的信息。关于中华人民共和国民法典的任何问题，您必须使用此工具!\",\n",
    ")\n",
    "tools = [retriever_tool]\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# https://smith.langchain.com/hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "# 运行代理\n",
    "agent_executor.invoke({\"input\": \"建设用地使用权是什么\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4db7cb042b37ae5d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
